{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f91391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 최신 데이터 파일: munpia_contest_ranking_20250605_225739.json\n",
      "✅ 데이터 로드 완료: 200개 작품\n",
      "📋 컬럼: ['crawl_rank', 'novel_url', 'novel_id', 'rank_number', 'author', 'title', 'genre', 'view_count', 'view_count_number', 'rank_change', 'rank_change_number', 'reading_rate', 'reading_rate_number']\n",
      "\n",
      "📊 기본 통계:\n",
      "   제목이 있는 작품: 200개\n",
      "   조회수가 있는 작품: 200개\n",
      "   연독률이 있는 작품: 152개\n"
     ]
    }
   ],
   "source": [
    "# 저장된 데이터 파일 찾기 및 로드\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 가장 최신 JSON 파일 찾기\n",
    "json_files = glob.glob('munpia_contest_ranking_*.json')\n",
    "if json_files:\n",
    "    latest_json = max(json_files, key=lambda x: x.split('_')[-1].replace('.json', ''))\n",
    "    print(f\"📁 최신 데이터 파일: {latest_json}\")\n",
    "    \n",
    "    # JSON 데이터 로드\n",
    "    with open(latest_json, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # DataFrame 생성\n",
    "    df = pd.DataFrame(data['rankings'])\n",
    "    \n",
    "    print(f\"✅ 데이터 로드 완료: {len(df)}개 작품\")\n",
    "    print(f\"📋 컬럼: {list(df.columns)}\")\n",
    "    \n",
    "    # 기본 정보 출력\n",
    "    print(f\"\\n📊 기본 통계:\")\n",
    "    print(f\"   제목이 있는 작품: {df['title'].notna().sum()}개\")\n",
    "    print(f\"   조회수가 있는 작품: {df['view_count_number'].notna().sum()}개\")\n",
    "    print(f\"   연독률이 있는 작품: {df['reading_rate_number'].notna().sum()}개\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 저장된 데이터 파일을 찾을 수 없습니다.\")\n",
    "    print(\"   먼저 파서를 실행하여 데이터를 수집해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a58406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "class MunpiaImprovedParser:\n",
    "    def __init__(self):\n",
    "        self.url = \"https://novel.munpia.com/page/hd.contest2025/group/contest/view/a/contest/list\"\n",
    "        self.html_file_path = r\"E:\\장난감 문피아\\문피아0611.html\"\n",
    "\n",
    "    def parse_local_file(self):\n",
    "        \"\"\"로컬 HTML 파일 파싱\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.html_file_path):\n",
    "                print(f\"❌ 파일이 존재하지 않습니다: {self.html_file_path}\")\n",
    "                return None\n",
    "\n",
    "            print(f\"📁 로컬 파일 읽기: {self.html_file_path}\")\n",
    "\n",
    "            # 인코딩 처리\n",
    "            html_content = None\n",
    "            for encoding in ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']:\n",
    "                try:\n",
    "                    with open(self.html_file_path, 'r', encoding=encoding) as f:\n",
    "                        html_content = f.read()\n",
    "                    print(f\"✅ 인코딩 성공: {encoding}\")\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            if not html_content:\n",
    "                print(\"❌ 파일 인코딩 실패\")\n",
    "                return None\n",
    "\n",
    "            print(f\"📄 HTML 크기: {len(html_content):,} 문자\")\n",
    "\n",
    "            return self.parse_html_content(html_content)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 파일 처리 실패: {e}\")\n",
    "            return None\n",
    "\n",
    "    def parse_html_content(self, html_content):\n",
    "        \"\"\"HTML 내용 파싱\"\"\"\n",
    "        try:\n",
    "            print(\"🔍 HTML 파싱 시작...\")\n",
    "\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "            # 페이지 제목 확인\n",
    "            title = soup.find('title')\n",
    "            if title:\n",
    "                print(f\"페이지 제목: {title.get_text()}\")\n",
    "\n",
    "            rankings = self.extract_rankings(soup)\n",
    "\n",
    "            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            result = {\n",
    "                'collection_time': current_time,\n",
    "                'total_works': len(rankings),\n",
    "                'rankings': rankings,\n",
    "                'url': self.url,\n",
    "                'method': 'local_file_parsing'\n",
    "            }\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ HTML 파싱 실패: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "    def extract_rankings(self, soup):\n",
    "        \"\"\"개선된 랭킹 데이터 추출\"\"\"\n",
    "        rankings = []\n",
    "\n",
    "        try:\n",
    "            print(\"🔍 랭킹 데이터 검색 중...\")\n",
    "\n",
    "            # best-rank-list-display 컨테이너 찾기\n",
    "            rank_container = soup.find('div', {'id': 'best-rank-list-display'})\n",
    "            if not rank_container:\n",
    "                print(\"❌ best-rank-list-display 컨테이너를 찾을 수 없습니다\")\n",
    "                return []\n",
    "\n",
    "            print(\"✅ best-rank-list-display 컨테이너 발견\")\n",
    "\n",
    "            # 소설 링크들 찾기 (munpia.com/숫자 패턴)\n",
    "            novel_links = []\n",
    "            all_links = rank_container.find_all('a', href=True)\n",
    "\n",
    "            for link in all_links:\n",
    "                href = link.get('href', '')\n",
    "                # novel.munpia.com/숫자 패턴 확인\n",
    "                if re.search(r'novel\\.munpia\\.com/\\d{6,}', href):\n",
    "                    novel_links.append(link)\n",
    "\n",
    "            print(f\"📚 발견된 소설 링크: {len(novel_links)}개\")\n",
    "\n",
    "            if not novel_links:\n",
    "                print(\"❌ 유효한 소설 링크를 찾을 수 없습니다\")\n",
    "                return []\n",
    "\n",
    "            # 각 소설 링크에서 데이터 추출\n",
    "            for idx, link in enumerate(novel_links, 1):\n",
    "                try:\n",
    "                    rank_data = self.extract_single_item(link, idx)\n",
    "                    if rank_data:\n",
    "                        rankings.append(rank_data)\n",
    "\n",
    "                        # 처음 20개 미리보기\n",
    "                        if idx <= 20:\n",
    "                            rank_num = rank_data.get('rank_number', '?')\n",
    "                            title = rank_data.get('title', 'N/A')[:30]\n",
    "                            author = rank_data.get('author', 'N/A')[:15]\n",
    "                            view_count = rank_data.get('view_count', 'N/A')\n",
    "                            genre = rank_data.get('genre', 'N/A')[:20]\n",
    "                            reading_rate = rank_data.get('reading_rate', 'N/A')\n",
    "\n",
    "                            print(f\"{rank_num:>3}. {title:<30} | {author:<15} | {view_count:>8} | {reading_rate:>7} | {genre}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"항목 {idx} 처리 중 오류: {e}\")\n",
    "                    continue\n",
    "\n",
    "            print(f\"✅ 총 {len(rankings)}개 작품 데이터 추출 완료\")\n",
    "            return rankings\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 랭킹 추출 실패: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return []\n",
    "\n",
    "    def extract_single_item(self, item, idx):\n",
    "        \"\"\"단일 항목 데이터 추출\"\"\"\n",
    "        try:\n",
    "            # URL 추출 및 정규화\n",
    "            novel_url = item.get('href', '')\n",
    "            if not novel_url.startswith('http'):\n",
    "                novel_url = 'https://' + novel_url if novel_url.startswith('novel.munpia.com') else 'https://novel.munpia.com' + novel_url\n",
    "\n",
    "            # 소설 ID 추출\n",
    "            novel_id_match = re.search(r'novel\\.munpia\\.com/(\\d+)', novel_url)\n",
    "            novel_id = novel_id_match.group(1) if novel_id_match else None\n",
    "\n",
    "            rank_data = {\n",
    "                'crawl_rank': idx,\n",
    "                'novel_url': novel_url,\n",
    "                'novel_id': novel_id\n",
    "            }\n",
    "\n",
    "            # 직접 자식 div들에서 클래스별로 데이터 추출\n",
    "            direct_divs = item.find_all('div', recursive=False)\n",
    "\n",
    "            for div in direct_divs:\n",
    "                div_classes = div.get('class', [])\n",
    "                if not div_classes:\n",
    "                    continue\n",
    "\n",
    "                class_name = ' '.join(div_classes)\n",
    "\n",
    "                # 순위 번호\n",
    "                if 'num' in class_name:\n",
    "                    rank_data['rank_number'] = self.clean_text(div.get_text())\n",
    "\n",
    "                # 작가명\n",
    "                elif 'author' in class_name:\n",
    "                    rank_data['author'] = self.clean_text(div.get_text())\n",
    "\n",
    "                # 제목\n",
    "                elif 'title' in class_name:\n",
    "                    title_span = div.find('span', class_='title-wrap')\n",
    "                    if title_span:\n",
    "                        rank_data['title'] = self.clean_text(title_span.get_text())\n",
    "                    else:\n",
    "                        # 다른 span이나 텍스트 확인\n",
    "                        span = div.find('span')\n",
    "                        if span:\n",
    "                            rank_data['title'] = self.clean_text(span.get_text())\n",
    "                        else:\n",
    "                            rank_data['title'] = self.clean_text(div.get_text())\n",
    "\n",
    "                # 장르\n",
    "                elif 'genre' in class_name:\n",
    "                    span = div.find('span')\n",
    "                    if span:\n",
    "                        rank_data['genre'] = self.clean_text(span.get_text())\n",
    "                    else:\n",
    "                        rank_data['genre'] = self.clean_text(div.get_text())\n",
    "\n",
    "                # 조회수\n",
    "                elif 'view-count' in class_name:\n",
    "                    view_text = self.clean_text(div.get_text())\n",
    "                    rank_data['view_count'] = view_text\n",
    "                    rank_data['view_count_number'] = self.extract_number(view_text)\n",
    "\n",
    "                # 순위 변동\n",
    "                elif 'rank-changes' in class_name:\n",
    "                    # SVG 태그 제거\n",
    "                    for svg in div.find_all('svg'):\n",
    "                        svg.decompose()\n",
    "\n",
    "                    change_text = self.clean_text(div.get_text())\n",
    "                    rank_data['rank_change'] = change_text\n",
    "\n",
    "                    # 숫자 변동 추출\n",
    "                    if change_text and re.match(r'^[+-]?\\d+$', change_text.strip()):\n",
    "                        try:\n",
    "                            rank_data['rank_change_number'] = int(change_text.strip())\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                # 연독률\n",
    "                elif 'percent' in class_name:\n",
    "                    span = div.find('span')\n",
    "                    if span:\n",
    "                        reading_rate = self.clean_text(span.get_text())\n",
    "                    else:\n",
    "                        reading_rate = self.clean_text(div.get_text())\n",
    "\n",
    "                    rank_data['reading_rate'] = reading_rate\n",
    "\n",
    "                    # 숫자로 변환\n",
    "                    if reading_rate and '%' in reading_rate:\n",
    "                        try:\n",
    "                            rate_num = float(reading_rate.replace('%', '').strip())\n",
    "                            if 0 <= rate_num <= 100:\n",
    "                                rank_data['reading_rate_number'] = rate_num\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "            # 필수 필드 확인\n",
    "            if rank_data.get('novel_id') and (rank_data.get('title') or rank_data.get('author')):\n",
    "                return rank_data\n",
    "\n",
    "            return None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"항목 추출 중 오류: {e}\")\n",
    "            return None\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        \"\"\"텍스트 정리\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "\n",
    "        text = re.sub(r'\\s+', ' ', str(text))\n",
    "        text = text.replace('\\xa0', ' ')\n",
    "        text = text.replace('\\u200b', '')\n",
    "        text = text.strip()\n",
    "\n",
    "        return text\n",
    "\n",
    "    def extract_number(self, text):\n",
    "        \"\"\"숫자 추출\"\"\"\n",
    "        if not text:\n",
    "            return 0\n",
    "\n",
    "        # 콤마가 포함된 숫자 패턴\n",
    "        numbers = re.findall(r'\\d{1,3}(?:,\\d{3})*', text)\n",
    "\n",
    "        if numbers:\n",
    "            try:\n",
    "                # 가장 큰 숫자 반환\n",
    "                max_num = 0\n",
    "                for num_str in numbers:\n",
    "                    try:\n",
    "                        num = int(num_str.replace(',', ''))\n",
    "                        if num > max_num:\n",
    "                            max_num = num\n",
    "                    except:\n",
    "                        continue\n",
    "                return max_num\n",
    "            except:\n",
    "                return 0\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def save_data(self, data):\n",
    "        \"\"\"데이터 저장\"\"\"\n",
    "        if not data or not data.get('rankings'):\n",
    "            print(\"❌ 저장할 데이터가 없습니다.\")\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "            # JSON 저장\n",
    "            json_filename = f\"munpia_contest_ranking_{timestamp}.json\"\n",
    "            with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "            # CSV 저장\n",
    "            df = pd.DataFrame(data['rankings'])\n",
    "            csv_filename = f\"munpia_contest_ranking_{timestamp}.csv\"\n",
    "            df.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "            print(f\"✅ 데이터 저장 완료:\")\n",
    "            print(f\"   📄 JSON: {json_filename}\")\n",
    "            print(f\"   📊 CSV: {csv_filename}\")\n",
    "\n",
    "            # 상세 통계\n",
    "            rankings = data['rankings']\n",
    "            print(f\"\\n📈 상세 통계:\")\n",
    "            print(f\"   총 작품 수: {len(rankings)}\")\n",
    "\n",
    "            if rankings:\n",
    "                # 필드별 추출 성공률\n",
    "                fields_stats = {\n",
    "                    'novel_id': len([r for r in rankings if r.get('novel_id')]),\n",
    "                    'title': len([r for r in rankings if r.get('title')]),\n",
    "                    'author': len([r for r in rankings if r.get('author')]),\n",
    "                    'genre': len([r for r in rankings if r.get('genre')]),\n",
    "                    'view_count': len([r for r in rankings if r.get('view_count')]),\n",
    "                    'reading_rate': len([r for r in rankings if r.get('reading_rate')]),\n",
    "                    'rank_change': len([r for r in rankings if r.get('rank_change')])\n",
    "                }\n",
    "\n",
    "                print(\"   필드별 추출 성공:\")\n",
    "                for field, count in fields_stats.items():\n",
    "                    percentage = (count / len(rankings)) * 100\n",
    "                    print(f\"     {field}: {count}개 ({percentage:.1f}%)\")\n",
    "\n",
    "                # 조회수 통계\n",
    "                view_counts = [r.get('view_count_number', 0) for r in rankings if r.get('view_count_number', 0) > 0]\n",
    "                if view_counts:\n",
    "                    print(f\"\\n   조회수 통계:\")\n",
    "                    print(f\"     평균: {sum(view_counts)/len(view_counts):,.0f}\")\n",
    "                    print(f\"     최고: {max(view_counts):,}\")\n",
    "                    print(f\"     최저: {min(view_counts):,}\")\n",
    "\n",
    "                # 독서율 통계\n",
    "                reading_rates = [r.get('reading_rate_number', 0) for r in rankings if r.get('reading_rate_number', 0) > 0]\n",
    "                if reading_rates:\n",
    "                    print(f\"\\n   독서율 통계:\")\n",
    "                    print(f\"     평균: {sum(reading_rates)/len(reading_rates):.2f}%\")\n",
    "                    print(f\"     최고: {max(reading_rates):.2f}%\")\n",
    "                    print(f\"     최저: {min(reading_rates):.2f}%\")\n",
    "\n",
    "            print(f\"\\n💾 파일이 저장되었습니다:\")\n",
    "            print(f\"   {os.path.abspath(json_filename)}\")\n",
    "            print(f\"   {os.path.abspath(csv_filename)}\")\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 저장 실패: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6884d7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 문피아 개선된 로컬 파일 파서 시작\n",
      "============================================================\n",
      "\n",
      "📋 개선사항:\n",
      "   ✅ 로컬 HTML 파일 직접 읽기\n",
      "   ✅ 정확한 HTML 구조 분석\n",
      "   ✅ 필드별 정확한 추출\n",
      "   ✅ 조회수, 연독률 숫자 변환\n",
      "   ✅ 상세 통계 제공\n",
      "\n",
      "📁 파일 경로: E:\\장난감 문피아\\문피아0611.html\n",
      "\n",
      "📁 로컬 파일 읽기: E:\\장난감 문피아\\문피아0611.html\n",
      "✅ 인코딩 성공: cp949\n",
      "📄 HTML 크기: 286,889 문자\n",
      "🔍 HTML 파싱 시작...\n",
      "🔍 랭킹 데이터 검색 중...\n",
      "✅ best-rank-list-display 컨테이너 발견\n",
      "📚 발견된 소설 링크: 200개\n",
      "  1. 방구석 경제학자                       | 페르세르크           |   10,022 |  63.18% | 현대판타지\n",
      "  2. 뇌각성 후 인생 역전                    | 연함™             |    7,831 |  37.03% | 현대판타지, 판타지\n",
      "  3. 자살 부대의 불사자는 착각당한다              | 풀드로우            |    7,437 |  63.21% | 퓨전, 현대판타지\n",
      "  4. 백수가 너무 유능하다.                   | 시하              |    7,138 |  59.31% | 현대판타지, 드라마\n",
      "  5. 하루에 2배씩 강해지는 헌터                | 캡슐호텔            |    6,427 |       - | 현대판타지, 퓨전\n",
      "  6. 삼류무사에서 천억 투수까지                 | 우림™             |    5,519 |  42.22% | 스포츠, 현대판타지\n",
      "  7. 초월급 투자자가 돈을 너무 잘 벎             | 늑타리요            |    5,449 |  61.73% | 현대판타지, 퓨전\n",
      "  8. 알 카포네 검은머리 데릴사위                | Merkava         |    5,417 |  65.92% | 대체역사, 현대판타지\n",
      "  9. 물리학도는 마법이 너무 쉽다                | 흠박              |    4,932 |  61.43% | 판타지, 퓨전\n",
      " 10. 귀환했더니 국가권력급 거물이 되었다            | 단열              |    4,098 |  33.64% | 현대판타지, 판타지\n",
      " 11. 성군 순종대왕 일대기                    | 리첼렌             |    3,829 |  56.81% | 대체역사, 판타지\n",
      " 12. 취미로 발롱도르                       | 피노키홍            |    3,575 |  46.28% | 스포츠, 현대판타지\n",
      " 13. 집구석 로켓배송                       | 아라만             |    3,120 |  56.63% | 현대판타지, 판타지\n",
      " 14. 내 뚝배기에 날아든 AI                  | 글쥐어짜기           |    2,814 |  74.97% | 현대판타지, 판타지\n",
      " 15. 축구 천재인 거 나만 모름                 | 시작의바다           |    2,735 |  76.72% | 스포츠\n",
      " 16. 2군 포수가 1군보다 잘함                 | 치규치규            |    2,524 |  37.13% | 스포츠, 현대판타지\n",
      " 17. 돈 버는 재능이 넘쳐나는 영주님              | 오토마톤G           |    2,455 |  64.93% | 판타지, 현대판타지\n",
      " 18. 101번째 드래프티는 야구가 너무 쉬움          | 밤카다             |    2,252 |  50.88% | 스포츠, 현대판타지\n",
      " 19. 토토충이 돈 복사 버그를 씀                | 긍정적마음           |    2,236 |  49.66% | 현대판타지, 스포츠\n",
      " 20. 수의사, 마물들의 명의가 됨                | 땅콩헌터            |    2,106 |  61.76% | 현대판타지, 퓨전\n",
      "✅ 총 200개 작품 데이터 추출 완료\n",
      "✅ 데이터 저장 완료:\n",
      "   📄 JSON: munpia_contest_ranking_20250611_215656.json\n",
      "   📊 CSV: munpia_contest_ranking_20250611_215656.csv\n",
      "\n",
      "📈 상세 통계:\n",
      "   총 작품 수: 200\n",
      "   필드별 추출 성공:\n",
      "     novel_id: 200개 (100.0%)\n",
      "     title: 200개 (100.0%)\n",
      "     author: 200개 (100.0%)\n",
      "     genre: 200개 (100.0%)\n",
      "     view_count: 200개 (100.0%)\n",
      "     reading_rate: 200개 (100.0%)\n",
      "     rank_change: 200개 (100.0%)\n",
      "\n",
      "   조회수 통계:\n",
      "     평균: 850\n",
      "     최고: 10,022\n",
      "     최저: 45\n",
      "\n",
      "   독서율 통계:\n",
      "     평균: 52.83%\n",
      "     최고: 86.10%\n",
      "     최저: 8.26%\n",
      "\n",
      "💾 파일이 저장되었습니다:\n",
      "   e:\\장난감 문피아\\munpia_contest_ranking_20250611_215656.json\n",
      "   e:\\장난감 문피아\\munpia_contest_ranking_20250611_215656.csv\n",
      "\n",
      "🎉 파싱 완료! 200개 작품 데이터 추출 및 저장 성공\n"
     ]
    }
   ],
   "source": [
    "# 개선된 파서 실행\n",
    "print(\"🚀 문피아 개선된 로컬 파일 파서 시작\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"📋 개선사항:\")\n",
    "print(\"   ✅ 로컬 HTML 파일 직접 읽기\")\n",
    "print(\"   ✅ 정확한 HTML 구조 분석\")\n",
    "print(\"   ✅ 필드별 정확한 추출\")\n",
    "print(\"   ✅ 조회수, 연독률 숫자 변환\")\n",
    "print(\"   ✅ 상세 통계 제공\")\n",
    "print()\n",
    "\n",
    "parser = MunpiaImprovedParser()\n",
    "print(f\"📁 파일 경로: {parser.html_file_path}\")\n",
    "print()\n",
    "\n",
    "result = parser.parse_local_file()\n",
    "\n",
    "if result:\n",
    "    success = parser.save_data(result)\n",
    "    if success:\n",
    "        print(f\"\\n🎉 파싱 완료! {result['total_works']}개 작품 데이터 추출 및 저장 성공\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️ 파싱은 성공했지만 저장 중 오류 발생\")\n",
    "else:\n",
    "    print(\"\\n❌ 파싱 실패\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
